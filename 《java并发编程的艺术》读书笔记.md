### 第1章　并发编程的挑战
-----
CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。

减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。

通过减少线上大量WAITING的线程，来减少上下文切换次数。
 
死锁：线程t1和线程t2互相等待对方释放锁。

##### 避免死锁的几个常见方法。
* 避免一个线程同时获取多个锁。
* 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
* 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。
* 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。

##### 什么是资源限制
资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。
##### 资源限制引发的问题
在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。
##### 解决资源限制问题
对于硬件资源限制，可以考虑使用集群并行执行程序。既然单机的资源有限制，那么就让程序在多机上运行。对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket 连接复用，或者在调用对方webservice接口获取数据时，只建立一个连接。
##### 在资源限制情况下进行并发编程
根据不同的资源限制调整程序的并发度。

### 第2章　Java并发机制的底层实现原理
-----
在多线程并发编程中synchronized和volatile都扮演着重要的角色，volatile是轻量级的 synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。

##### volatile的定义与实现原理
Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。

##### CPU的术语定义
内存屏障：是一组处理指令，用于实现对内存操作的顺序限制。

##### volatile的两条实现原则
1）Lock前缀指令会引起处理器缓存回写到内存。
2）一个处理器的缓存回写到内存会导致其他处理器的缓存无效。

##### synchronized的实现原理与应用
在多线程并发编程中synchronized一直是元老级角色，很多人都会称呼它为重量级锁。但是，随着Java SE 1.6对synchronized进行了各种优化之后，有些情况下它就并不那么重了。
Java中的每一个对象都可以作为锁。具体表现为以下3种形式。
* 对于普通同步方法，锁是当前实例对象。
* 对于静态同步方法，锁是当前类的Class对象。
* 对于同步方法块，锁是Synchonized括号里配置的对象。

从JVM规范中可以看到Synchonized在JVM里的实现原理，JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter 和monitorexit指令实现的，而方法同步是使用另外一种方式实现的，细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。
monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter 指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。

synchronized用的锁是存在Java对象头里的。
 
Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄和锁标记位。
 
在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。
 
在64位虚拟机下，Mark Word是64bit大小的。
 

##### 锁的升级与对比
在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。<br>  
关于这几种状态的具体情况请见：[浅谈偏向锁、轻量级锁、重量级锁](https://github.com/Mathilda11/Java-Notes/blob/master/%E9%94%81.md)

##### 原子操作的实现原理
原子（atomic）本意是“不能被进一步分割的最小粒子”，而原子操作（atomic operation）意 为“不可被中断的一个或一系列操作”。
处理器如何实现原子操作
（1）使用总线锁保证原子性
第一个机制是通过总线锁保证原子性。处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。
（2）使用缓存锁保证原子性
第二个机制是通过缓存锁定来保证原子性。

##### Java如何实现原子操作
* 使用循环CAS实现原子操作 
* CAS实现原子操作的三大问题
  * ABA问题。ABA问题的解决思路就是使用版本号。从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。
  * 循环时间长开销大。
  * 只能保证一个共享变量的原子操作。
* 使用锁机制实现原子操作

### 第3章　Java内存模型
-----
##### 并发编程模型的两个关键问题
* 线程之间如何通信
* 线程之间如何同步（这里的线程是指并发执行的活动实体）。
通信是指线程之间以何种机制来交换信息。
在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。
同步是指程序中用于控制不同线程间操作发生相对顺序的机制。

###### Java内存模型的抽象结构
在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享。局部变量，方法定义参数和异常处理器参数不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。
Java线程之间的通信由Java内存模型（简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。

##### 从源代码到指令序列的重排序
重排序分3种类型
* 编译器优化的重排序。
* 指令级并行的重排序。
* 内存系统的重排序。

由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写-读操作进行重排序。

为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类。

##### happens-before简介
在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。
与程序员密切相关的happens-before规则如下。
* 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
* 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
* volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
* 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
一个happens-before规则对应于一个或多个编译器和处理器重排序规则。

##### 重排序
重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段。

##### 数据依赖性
如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。

##### as-if-serial语义
as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程） 程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。

##### 顺序一致性内存模型
1）一个线程中的所有操作必须按照程序的顺序来执行。
2）（不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。

未同步程序在JMM中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，Null，False），JMM保证线程读操作读取到的值不会无中生有的冒出来。

##### volatile变量自身具有下列特性。
* 可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。
* 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。

从JSR-133开始（即从JDK5开始），volatile变量的写-读可以实现线程之间的通信。
从内存语义的角度来说，volatile的写-读与锁的释放-获取有相同的内存效果：volatile写和锁的释放有相同的内存语义；volatile读与锁的获取有相同的内存语义。

##### volatile写的内存语义
当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主内存。

##### volatile读的内存语义
当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量。

##### volatile写和volatile读的内存语义总结
* 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程
发出了（其对共享变量所做修改的）消息。
* 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile
变量之前对共享变量所做修改的）消息。
*线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过 主内存向线程B发送消息。

##### volatile内存语义的实现
JMM会分别限制这编译器重排序和处理器重排序。
* 限制编译器重排序
  * 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保 volatile写之前的操作不会被编译器重排序到volatile写之后。
  * 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保 volatile读之后的操作不会被编译器重排序到volatile读之前。
  * 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。
* 限制处理器重排序
编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。

锁是Java并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。
##### 锁的释放和获取的内存语义
当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的 临界区代码必须从主内存中读取共享变量。

对比锁释放-获取的内存语义与volatile写-读的内存语义可以看出：锁释放与volatile写有相同的内存语义；锁获取与volatile读有相同的内存语义。

##### 锁内存语义的实现
在ReentrantLock中，调用lock()方法获取锁；调用unlock()方法释放锁。
ReentrantLock的实现依赖于Java同步器框架AbstractQueuedSynchronizer（简称为 AQS）。AQS使用一个整型的volatile变量（命名为state）来维护同步状态，马上我们会看到，这个volatile变量是ReentrantLock内存语义实现的关键。
ReentrantLock分为公平锁和非公平锁。

##### 公平锁和非公平锁的内存语义总结。
* 公平锁和非公平锁释放时，最后都要写一个volatile变量state。
* 公平锁获取时，首先会去读volatile变量。
* 非公平锁获取时，首先会用CAS更新volatile变量，这个操作同时具有volatile读和volatile写的内存语义。

##### CAS具有volatile读和volatile写的内存语义
intel的手册对lock前缀的说明如下。
* 确保对内存的读-改-写操作原子执行。
* 禁止该指令，与之前和之后的读和写指令重排序。
* 把写缓冲区中的所有数据刷新到内存中。

##### 锁释放-获取的内存语义的实现至少有下面两种方式。
* 利用volatile变量的写-读所具有的内存语义。
* 利用CAS所附带的volatile读和volatile写的内存语义。

##### concurrent包的实现
如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式。
* 首先，声明共享变量为volatile。
* 然后，使用CAS的原子条件更新来实现线程之间的同步。
* 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent 包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。

##### final域的重排序规则
对于final域，编译器和处理器要遵守两个重排序规则。
* 在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。
* 初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。

##### happens-before
JSR-133使用happens-before的概念来指定两个操作之间的执行顺序。由于这两个操作可以在一个线程之内，也可以是在不同线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可
见）。

##### happens-before关系的定义
* 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作
可见，而且第一个操作的执行顺序排在第二个操作之前。
* 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照 happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系 来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。
happens-before关系本质上和as-if-serial语义是一回事。as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。

##### happens-before规则
* 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
* 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
* volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的
读。
* 传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。
* start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的 ThreadB.start()操作happens-before于线程B中的任意操作。
* join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作 happens-before于线程A从ThreadB.join()操作成功返回。

##### 双重检查锁定与延迟初始化
在Java多线程程序中，有时候需要采用延迟初始化来降低初始化类和创建对象的开销。双重检查锁定是常见的延迟初始化技术，但它是一个错误的用法（重排序问题）。

##### 两个办法实现线程安全的延迟初始化
* 基于volatile的解决方案
  * 把instance声明为volatile型，就可以实现线程安全的延迟初始化。当声明对象的引用为volatile后，重排序，在多线程环境中将会被禁止。
  * 本质上是通过禁止重排序，来保证线程安全的延迟初始化。
* 基于类初始化的解决方案
为了更好的说明类初始化过程中的同步处理机制，笔者人为的把类初始化的处理过程分为了5个阶段）。
  * 第1阶段：通过在Class对象上同步（即获取Class对象的初始化锁），来控制类或接口的初始化。这个获取锁的线程会一直等待，直到当前线程能够获取到这个初始化锁。
  * 第2阶段：线程A执行类的初始化，同时线程B在初始化锁对应的condition上等待。
  * 第3阶段：线程A设置state=initialized，然后唤醒在condition中等待的所有线程。
  * 第4阶段：线程B结束类的初始化处理。
  * 第5阶段：线程C执行类的初始化的处理。
  * 本质上是允许重排序，但不允许非构造线程（这里指线程B）“看到”这个重排序。

